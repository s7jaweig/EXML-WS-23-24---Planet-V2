{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load libraries\n",
    "\n",
    "#Imort modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.image as img\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import s2sphere\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load the Tensorflow Hub modul\n",
    "module = hub.Module(\"https://www.kaggle.com/models/google/planet-v2/frameworks/TensorFlow1/variations/planet-vision-classifier-planet-v2/versions/1\")\n",
    "height, width = hub.get_expected_image_size(module)\n",
    "\n",
    "# load labelmap\n",
    "labelmap = pd.read_csv(\"planet_v2_labelmap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Needed Functions\n",
    "\n",
    "# find x maxima\n",
    "def find_x_maxima(array, x):\n",
    "    indices = np.argsort(array)[-x:][::-1]  # indices of maximas\n",
    "    maxima = array[indices]  # values of maximas\n",
    "    return indices, maxima\n",
    "\n",
    "# Crates txt for Geoplots\n",
    "def text_datei(idx_nummer,score,dateiname):\n",
    "    with open(\"results/Geoplot-\"+dateiname+\".txt\",'w') as datei:\n",
    "        for i in range(5):\n",
    "            id_nummer=idx_nummer[i]\n",
    "\n",
    "            # get cellnumber in Labelmap\n",
    "            corresponding_row = labelmap[labelmap['id'] == id_nummer]\n",
    "            s2_cell_id_hex = corresponding_row['S2CellId'].values[0]\n",
    "\n",
    "            # Get Coordinates of the Cells\n",
    "            s2_cell_id = s2sphere.CellId.from_token(s2_cell_id_hex)\n",
    "            s2_cell = s2sphere.Cell(s2_cell_id)\n",
    "            vertices = [s2sphere.LatLng.from_point(s2_cell.get_vertex(i)) for i in range(4)]\n",
    "            latitudes, longitudes = zip(*[(vertex.lat().degrees, vertex.lng().degrees) for vertex in vertices])\n",
    "            latitudes_array = np.array(latitudes)\n",
    "            longitudes_array = np.array(longitudes)\n",
    "\n",
    "            # Write txt\n",
    "            datei.write(str(latitudes_array[:]) + '\\n')\n",
    "            datei.write(str(longitudes_array[:]) + '\\n')\n",
    "            datei.write(str(score[i]) + '\\n')\n",
    "            datei.write(str(id_nummer)+ '\\n')\n",
    "    \n",
    "# Function for Geoplots\n",
    "def bildanalyse_geoplots(imagenamen):\n",
    "    \n",
    "    # Load and resize images\n",
    "    images = np.zeros([len(imagenamen),299,299,3])\n",
    "    for i in range(len(imagenamen)):\n",
    "        image = img.imread(\"images/\"+ imagenamen[i])\n",
    "        image = image[:,:,0:3]\n",
    "        image_res = resize(image, (299, 299))\n",
    "        images[i,:,:,:] = image_res[:,:,:]\n",
    "    print(\"Images loaded\")\n",
    "\n",
    "    # Run PlaNet\n",
    "    features = module(images)\n",
    "    print('Network done')\n",
    "\n",
    "    # create Numpy-Array\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        features_np = sess.run(features)\n",
    "    print('NP-Array created')\n",
    "\n",
    "    # Generate txt-data\n",
    "    for i in range(len(imagenamen)):\n",
    "        maxima_id,maxima_score = find_x_maxima(features_np[i,:],5)\n",
    "        text_datei(maxima_id,maxima_score,imagenamen[i])\n",
    "    print('txt generated')\n",
    "\n",
    "\n",
    "# Function for Superpixel\n",
    "def bildanalyse_superpixel(imagename,nmax,endung):\n",
    "    \n",
    "    # Load images\n",
    "    images = np.zeros([nmax+1,299,299,3])\n",
    "    # original image\n",
    "    image = img.imread(\"images/Segmented_imgs_\"+imagename+\"/Segmented\"+endung)\n",
    "    image = image[:,:,0:3]\n",
    "    image_res = resize(image, (299, 299))\n",
    "    images[0,:,:,:] = image_res[:,:,:]\n",
    "    # superpixel images\n",
    "    for i in range(nmax):\n",
    "        image = img.imread(\"images/Segmented_imgs_\"+imagename+\"/Segmented_\"+str(i+1)+\".png\")\n",
    "        image = image[:,:,0:3]\n",
    "        image_res = resize(image, (299, 299))\n",
    "        images[i+1,:,:,:] = image_res[:,:,:]\n",
    "    print('- Images loaded')\n",
    "    \n",
    "    # Run PlaNet\n",
    "    features = module(images)\n",
    "    print('- Network done')\n",
    "\n",
    "    # create Numpy-Array\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        features_np = sess.run(features)\n",
    "    print('- NP-Array created')\n",
    "        \n",
    "    # generate txt\n",
    "    cell_id = np.argsort(features_np[0,:])[-1:][::-1]\n",
    "    cell_prop = features_np[1:,cell_id]\n",
    "    with open(\"results/Segmented-\"+imagename+\".txt\",'w') as datei:\n",
    "        datei.write(str(cell_id)+'\\n')\n",
    "        datei.write(str(cell_prop[:,0])+'\\n')\n",
    "    print('- txt generated')\n",
    "    \n",
    "# Function for Heatmap\n",
    "def bildanalyse_heatmap(imagename,nmax,endung):\n",
    "    \n",
    "    # Load images\n",
    "    images = np.zeros([nmax+1,299,299,3])\n",
    "    # original image\n",
    "    image = img.imread(\"images/output_\" + imagename + \"/\"+ imagename + endung)\n",
    "    image = image[:,:,0:3]\n",
    "    image_res = resize(image, (299, 299))\n",
    "    images[0,:,:,:] = image_res[:,:,:]\n",
    "    # heatmap images\n",
    "    for i in range(nmax):\n",
    "        image = img.imread(\"images/output_\"+imagename+\"/\"+imagename+\"_output_\"+str(i)+\".jpg\")\n",
    "        image = image[:,:,0:3]\n",
    "        image_res = resize(image, (299, 299))\n",
    "        images[i+1,:,:,:] = image_res[:,:,:]\n",
    "    print('- Images loaded')\n",
    "\n",
    "    # Run PlaNet\n",
    "    features = module(images)\n",
    "    print('- Network done')\n",
    "\n",
    "    # create Numpy-Array\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        features_np = sess.run(features)\n",
    "    print('- NP-Array created')\n",
    "        \n",
    "    # generate txt\n",
    "    cell_id = np.argsort(features_np[0,:])[-1:][::-1]\n",
    "    cell_prop = features_np[1:,cell_id]\n",
    "    with open(\"results/Heatmap-\"+imagename+\".txt\",'w') as datei:\n",
    "        datei.write(str(cell_id)+'\\n')\n",
    "        datei.write(str(cell_prop[:,0])+'\\n')\n",
    "    print('- txt generated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture See_Sommer is processed: 1 from 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Images loaded\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Network done\n",
      "- NP-Array created\n",
      "- txt generated\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: for Heatmaps\n",
    "names = [\"See_Sommer\"] # names of the Images    \n",
    "datatyp = [\".jpg\"] # imagetyp\n",
    "n = [96] # Number of Heatmap Images (maximum number in the names + 1)\n",
    "\n",
    "for i in range(0,len(names)):\n",
    "    print(('Picture '+ names[i]+' is processed: '+str(i+1)+' from '+str(len(names))))\n",
    "    bildanalyse_heatmap(names[i],n[i],datatyp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture Sommer is processed: 1 from 1\n",
      "- Images loaded\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Network done\n",
      "- NP-Array created\n",
      "- txt generated\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: for Superpixel\n",
    "names = [\"Sommer\"] # names of the Images    \n",
    "datatyp = [\".png\"] # imagetyp\n",
    "n = [15] # Number of superpixel Images (maximum number in the names)\n",
    "\n",
    "for i in range(0,len(names)):\n",
    "    print(('Picture '+ names[i]+' is processed: '+str(i+1)+' from '+str(len(names))))\n",
    "    bildanalyse_superpixel(names[i],n[i],datatyp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network done\n",
      "NP-Array created\n",
      "txt generated\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: for Geoplots\n",
    "images=[\"See_Sommer.jpg\"] # names of the images\n",
    "bildanalyse_geoplots(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

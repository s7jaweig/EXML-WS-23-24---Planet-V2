{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Imort modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import s2sphere\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load the Tensorflow Hub modul\n",
    "module = hub.Module(\"https://www.kaggle.com/models/google/planet-v2/frameworks/TensorFlow1/variations/planet-vision-classifier-planet-v2/versions/1\")\n",
    "height, width = hub.get_expected_image_size(module)\n",
    "\n",
    "# Labelmap einladen\n",
    "labelmap = pd.read_csv(\"planet_v2_labelmap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Bestimmung von x Maxima\n",
    "def find_x_maxima(array, x):\n",
    "    indices = np.argsort(array)[-x:][::-1]  # Indizes der x größten Elemente\n",
    "    maxima = array[indices]  # Werte der x größten Elemente\n",
    "\n",
    "    return indices, maxima\n",
    "\n",
    "# Schreibt Ergebnisse fur ein Bild in txt Datei um diese in Matlab zu plotten\n",
    "def text_datei(idx_nummer,score,dateiname):\n",
    "    with open(\"Ergebnisse/Ergebnis-\"+dateiname+\".txt\",'w') as datei:\n",
    "        for i in range(5):\n",
    "            id_nummer=idx_nummer[i]\n",
    "            # Zellennummer im Labelmap finden\n",
    "            corresponding_row = labelmap[labelmap['id'] == id_nummer]\n",
    "            s2_cell_id_hex = corresponding_row['S2CellId'].values[0]\n",
    "\n",
    "            # Konvertieren Sie die Hexadezimal-Zeichenfolge in einen S2-Zellen-ID-Objekt\n",
    "            s2_cell_id = s2sphere.CellId.from_token(s2_cell_id_hex)\n",
    "\n",
    "            # Erstellen Sie eine S2-Zelle aus der S2-Zellen-ID\n",
    "            s2_cell = s2sphere.Cell(s2_cell_id)\n",
    "\n",
    "            # Extrahieren Sie die Ecken der Zelle\n",
    "            vertices = [s2sphere.LatLng.from_point(s2_cell.get_vertex(i)) for i in range(4)]\n",
    "\n",
    "            # Konvertieren Sie die Koordinaten in Arrays\n",
    "            latitudes, longitudes = zip(*[(vertex.lat().degrees, vertex.lng().degrees) for vertex in vertices])\n",
    "            \n",
    "            latitudes_array = np.array(latitudes)\n",
    "            longitudes_array = np.array(longitudes)\n",
    "\n",
    "            datei.write(str(latitudes_array[:]) + '\\n')\n",
    "            datei.write(str(longitudes_array[:]) + '\\n')\n",
    "            datei.write(str(score[i]) + '\\n')\n",
    "            datei.write(str(id_nummer)+ '\\n')\n",
    "    \n",
    "# Wertet einzelne Bilder aus, um daraus Plots zu erzeugen\n",
    "def bildanalyse(imagenamen,cellnr):\n",
    "    images = np.zeros([len(imagenamen),299,299,3])\n",
    "    for i in range(len(imagenamen)):\n",
    "        # Bild einladen und passende Groesse erstellen\n",
    "        image = img.imread(\"images/\"+ imagenamen[i])\n",
    "        #image = img.imread(imagenamen[i])\n",
    "        image = image[:,:,0:3]\n",
    "        image_res = resize(image, (299, 299)) # Bilder brauchen die Groesse 299x299 mit 3 Kanaelen zwischen 0 und 1\n",
    "        images[i,:,:,:] = image_res[:,:,:] # Network kann mehrere Bilder gleichzeitig nehmen -> shape [n,299,299,3]\n",
    "\n",
    "    # Neuronales Netz anwenden\n",
    "    features = module(images)\n",
    "\n",
    "    print('Netzwerk fertig')\n",
    "\n",
    "    # in Numpy Array umwandeln\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        # Führen Sie die Sitzung aus und erhalten Sie den Wert des Tensors\n",
    "        features_np = sess.run(features)\n",
    "\n",
    "    print('NP-Array erzeugt')\n",
    "\n",
    "    if cellnr==0:\n",
    "        for i in range(len(imagenamen)):\n",
    "            maxima_id,maxima_score = find_x_maxima(features_np[i,:],5)\n",
    "            text_datei(maxima_id,maxima_score,imagenamen[i])\n",
    "        print('Texdateien abgespeichert')\n",
    "    else:\n",
    "        print(features_np[:,cellnr])\n",
    "    \n",
    "\n",
    "    return features_np\n",
    "\n",
    "# Wertet ein Bild mit verschiedenen scharzen Kaesten fuer Heatmap aus\n",
    "def bildanalyse_heatmap(imagename,nmax,endung):\n",
    "    images = np.zeros([nmax+1,299,299,3])\n",
    "\n",
    "    # Original Bild \n",
    "    #image = img.imread(\"images/\"+ imagename+\".png\")\n",
    "    #image = img.imread(\"images/Segmented_imgs_\"+imagename+\"/Segmented.png\")\n",
    "    image = img.imread(\"images/output_\"+imagename+\"/\"+imagename+endung)\n",
    "    image = image[:,:,0:3]\n",
    "    image_res = resize(image, (299, 299)) # Bilder brauchen die Groesse 299x299 mit 3 Kanaelen zwischen 0 und 1\n",
    "    images[0,:,:,:] = image_res[:,:,:] # Network kann mehrere Bilder gleichzeitig nehmen -> shape [n,299,299,3]\n",
    "\n",
    "\n",
    "    for i in range(nmax):\n",
    "        # Bild einladen und passende Groesse erstellen\n",
    "        #image = img.imread(\"images/\"+ imagename + '_output_' + str(i) + '.png')\n",
    "        #image = img.imread(\"images/\"+ imagename + '_' + str(i+1) + '.png')\n",
    "        #image = img.imread(\"images/Segmented_imgs_\"+imagename+\"/Segmented_\"+str(i+1)+\".png\")\n",
    "        image = img.imread(\"images/output_\"+imagename+\"/\"+imagename+\"_resize_output_\"+str(i)+\".jpg\")\n",
    "        #image = img.imread(\"images/output_\"+imagename+\"/\"+imagename+\"_output_\"+str(i)+endung)\n",
    "        image = image[:,:,0:3]\n",
    "        image_res = resize(image, (299, 299)) # Bilder brauchen die Groesse 299x299 mit 3 Kanaelen zwischen 0 und 1\n",
    "        images[i+1,:,:,:] = image_res[:,:,:] # Network kann mehrere Bilder gleichzeitig nehmen -> shape [n,299,299,3]\n",
    "\n",
    "    plt.imshow(images[-1,:,:,:])\n",
    "    plt.show\n",
    "\n",
    "    print('Bilder eingelesen')\n",
    "    \n",
    "    # Neuronales Netz anwenden\n",
    "    features = module(images)\n",
    "\n",
    "    print('Netzwerk fertig')\n",
    "\n",
    "    # in Numpy Array umwandeln\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        # Führen Sie die Sitzung aus und erhalten Sie den Wert des Tensors\n",
    "        features_np = sess.run(features)\n",
    "\n",
    "    print('NP-Array erzeugt')\n",
    "\n",
    "    cell_id = np.argsort(features_np[0,:])[-1:][::-1]\n",
    "    cell_prop = features_np[1:,cell_id]\n",
    "\n",
    "    with open(\"Ergebnisse/Heatmap-\"+imagename+\".txt\",'w') as datei:\n",
    "        datei.write(str(cell_id)+'\\n')\n",
    "        datei.write(str(cell_prop[:,0])+'\\n')\n",
    "\n",
    "    print('Texdateien abgespeichert')\n",
    "\n",
    "    return features_np, cell_prop\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild Loewe_Krueger wird prozessiert: 0 von 3\n",
      "Bilder eingelesen\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netzwerk fertig\n",
      "NP-Array erzeugt\n",
      "Texdateien abgespeichert\n",
      "[0.12720557 0.1333016  0.11340791 0.10565481 0.09901606 0.08906078\n",
      " 0.10108333 0.09069698 0.10753006 0.09622489 0.09400484 0.09783579\n",
      " 0.09632114 0.08261222 0.09380652 0.08881146 0.1027843  0.07321994\n",
      " 0.07574269 0.10277586 0.10464382 0.08782063 0.08794332 0.09397079\n",
      " 0.09994581 0.09146746 0.08687489 0.10389145 0.09524098 0.07425065\n",
      " 0.07933933 0.09154207 0.0845759  0.10452414 0.11505503 0.10614055\n",
      " 0.09894593 0.07206841 0.06376991 0.09667823 0.08967791 0.09557208\n",
      " 0.11368935 0.10484755 0.05751393 0.0753784  0.07062591 0.09473878\n",
      " 0.08158936 0.09432796 0.09086132 0.12285332 0.06224329 0.10643497\n",
      " 0.07950412 0.09540687 0.06948511 0.08676369 0.04814725 0.06232323\n",
      " 0.05287928 0.09086021 0.10736245 0.09726776 0.08079905 0.09202757\n",
      " 0.07329777 0.07247356 0.05506494 0.0971746  0.10877846 0.08887904\n",
      " 0.09871556 0.08529006 0.08167348 0.07970084 0.09265506 0.09583975\n",
      " 0.09272781 0.08427945 0.10381697 0.08894088 0.09963899 0.07731722\n",
      " 0.10252951 0.09284417 0.07980631 0.06700069 0.0756141  0.09006763\n",
      " 0.09329171 0.08368499 0.09318503 0.09631287 0.09429608 0.0819165 ]\n",
      "Bild Matterhorn wird prozessiert: 1 von 3\n"
     ]
    }
   ],
   "source": [
    "#names = [\"Kennedybruecke\",\"Kirschbluete\",\"london\",\"Muenster\",\"Nussallee\",\"Rathaus\",\"Universitaet\",\"Statue\",\"Winter\",\"Sommer\"]\n",
    "#n = [14,11,11,13,12,16,13,13,15,15,15]\n",
    "\n",
    "#names = [\"B_Kennedybruecke\",\"B_Kirschbluete\",\"B_Muenster\",\"B_Nussallee\",\"B_Rathaus\",\"B_Universitaet\",\"B_Statue\",\"london\",\"See_Sommer\",\"See_Winter\"]\n",
    "#endungen = [\".jpg\",\".jpg\",\".jpg\",\".png\",\".jpg\",\".jpg\",\".jpg\",\".png\",\".jpg\",\".jpg\"]\n",
    "#n = [96,96,96,96,96,96,96,100,96,96]\n",
    "\n",
    "#names = [\"Loewe\",\"Matterhorn\",\"Zoo\"]\n",
    "#n = [16,11,11]\n",
    "names = [\"Loewe_Krueger\",\"Matterhorn\",\"Loewe_Zoo\"]\n",
    "n = [96,96,96]\n",
    "\n",
    "for i in range(0,len(names)):\n",
    "    print(('Bild '+ names[i]+' wird prozessiert: '+str(i)+' von '+str(len(names))))\n",
    "    features_np, cell_prop = bildanalyse_heatmap(names[i],n[i],\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netzwerk fertig\n",
      "NP-Array erzeugt\n",
      "Texdateien abgespeichert\n"
     ]
    }
   ],
   "source": [
    "#images=[\"london.png\",\"See_Sommer.jpg\",\"See_Winter.jpg\",\"B_Kennedybruecke.jpg\", \"B_Kirschbluete.jpg\",\"B_Muenster.jpg\",\"B_Nussallee.png\",\"B_Rathaus.jpg\",\"B_Statue.jpg\",\"B_Universitaet.jpg\"]\n",
    "images=[\"Loewe_Krueger.png\",\"Loewe_Zoo.png\",\"Matterhorn.png\"]\n",
    "features_ein = bildanalyse(images,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
